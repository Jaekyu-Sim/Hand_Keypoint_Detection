{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import cv2\n",
    "import ast\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import collections\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import Network as net\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "def make_batch(img_path, anno_data, batch_size = 16):\n",
    "    num_of_data = len(img_path)\n",
    "    index = np.arange(0, num_of_data)\n",
    "    np.random.shuffle(index)\n",
    "    index = index[:batch_size]\n",
    "    \n",
    "    shuffled_img_data = [img_path[i] for i in index]\n",
    "    #shuffled_anno_data = [anno_data[j] for j in index]\n",
    "    shuffled_anno_data = [[anno_data[j:j+1]][0][0] for j in index]\n",
    "    #shuffled_anno_data = [anno_data[j:j+1][0][0][0] for j in index]\n",
    "    \n",
    "    return np.asarray(shuffled_img_data), np.asarray(shuffled_anno_data)\n",
    "\n",
    "def load_data():\n",
    "    joint_result = np.load('./dataset/Hands/hand_labels/Annotation/hands_joint_data.npy')\n",
    "    train_file_list = np.load('./dataset/Hands/hand_labels/Annotation/Resized_hands_img_data.npy')\n",
    "    return train_file_list, joint_result\n",
    "\n",
    "def path_to_image(img_path, batch_size):\n",
    "    #buffer 선언\n",
    "    image_data = np.zeros((batch_size, 356, 356, 3), np.uint8)\n",
    "    \n",
    "    index = 0\n",
    "    for img in (img_path):\n",
    "        image_data[index] = cv2.imread(img)\n",
    "        index = index + 1\n",
    "\n",
    "    return image_data\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "class OpenPose_Demo_Hand():\n",
    "    def __init__(self, sess, batch_size):\n",
    "        self.sess = sess\n",
    "        self.batch_size = batch_size\n",
    "        self.img_input = tf.placeholder(dtype=tf.float32, shape=[None, 356, 356, 3])\n",
    "        self.confidencemap = tf.placeholder(dtype = tf.float32, shape = [None, 356, 356, 22])\n",
    "        self.PAFs = tf.placeholder(dtype = tf.float32, shape = [None, 356, 356, 44])\n",
    "        \n",
    "        self.model()\n",
    "        print(\"open pose demo init complete\")\n",
    "        \n",
    "    def model(self):\n",
    "        self.Feature = net.block_vgg_19(self.img_input)#stage0_data - None, 44, 44, 512\n",
    "        \n",
    "        self.stage1_branch = net.block_stage_1_hand(self.Feature)#stage1_branch - None, 44, 44, 34\n",
    "        self.stage1_data = tf.concat([self.stage1_branch, self.Feature], 3)\n",
    "        \n",
    "        self.stage2_branch = net.block_stage_2_hand(self.stage1_data)#stage2_branch - None, 44, 44, 34\n",
    "        self.stage2_data = tf.concat([self.stage2_branch, self.Feature], 3)\n",
    "        \n",
    "        self.stage3_branch = net.block_stage_3_hand(self.stage2_data)#stage3_branch - None, 44, 44, 34\n",
    "        self.stage3_data = tf.concat([self.stage3_branch, self.Feature], 3)\n",
    "        \n",
    "        self.stage4_branch = net.block_stage_4_hand(self.stage3_data)#stage4_branch - None, 44, 44, 34\n",
    "        self.stage4_data = tf.concat([self.stage4_branch, self.Feature], 3)\n",
    "        \n",
    "        self.stage5_branch = net.block_stage_5_hand(self.stage4_data)#stage5_branch - None, 44, 44, 17\n",
    "        #self.stage5_data = tf.concat([self.stage5_branch, stage0_data], 3)\n",
    "        \n",
    "        self.stage6_branch = net.block_stage_6_hand(self.stage5_branch)#stage6_branch - None, 44, 44, 17\n",
    "        #self.stage6_data = tf.concat([self.stage6_branch, stage0_data], 3)\n",
    "        \n",
    "    \n",
    "    def demo_test(self, input_data):\n",
    "        input_img = input_data\n",
    "        SAVE_PATH = \"C:/Users/SimJaekyu/Documents/Jupyter Notebook/Pose_Estimation_with_Hand/Weight_Hand/Weight.ckpt\"\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        try:\n",
    "            saver.restore(self.sess, SAVE_PATH)\n",
    "            print(\"Training Weight load\")\n",
    "        except:\n",
    "            print(\"No Training Weight exit\")\n",
    "            \n",
    "        confidencemap, PAFs = self.sess.run([self.stage6_branch, self.stage4_branch], feed_dict = {self.img_input : input_img})\n",
    "        \n",
    "        return confidencemap, PAFs\n",
    "            \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
